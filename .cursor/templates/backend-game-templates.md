# 游꿡 Backend Game Server Templates

**햗햟햠햩쮏쫨 햢햩혪 real-time game servers**

## 游꿡 game_server.go

```go
// Issue: #123
package server

import (
    "context"
    "runtime"
    "sync"
    "sync/atomic"
    "time"
)

// 뤯햑햊햎햊행햃햕햊햞: 햟쒫쟳혧햫혦햧 struct alignment
type Player struct {
    ID       uint64      // 8 bytes
    Position Vector3     // 12 bytes (3x float32)
    Rotation Quaternion  // 16 bytes (4x float32)
    Health   int32       // 4 bytes
    Level    uint16      // 2 bytes
    IsActive bool        // 1 byte
    _        byte        // 1 byte padding (explicit)
} // Total: 44 bytes (쮏혝햦햪햟햩혧햫)

type GameServer struct {
    playerCount atomic.Int32
    tickRate    time.Duration
    
    // 뤯햑햊햎햊행햃햕햊햞: Spatial grid
    spatialGrid *SpatialGrid
    
    // 뤯햑햊햎햊행햃햕햊햞: Worker pool
    workerPool *WorkerPool
    
    // 뤯햑햊햎햊행햃햕햊햞: Object pools
    updatePool sync.Pool
    packetPool sync.Pool
}

func NewGameServer() *GameServer {
    // 뤯햑햊햎햊행햃햕햊햞: GC tuning 햢햩혪 game server
    runtime.GOMAXPROCS(runtime.NumCPU() - 1)
    
    return &GameServer{
        tickRate:    16 * time.Millisecond, // 60 Hz default
        spatialGrid: NewSpatialGrid(100.0), // 100m cells
        workerPool:  NewWorkerPool(1000),   // Max 1000 workers
        
        updatePool: sync.Pool{
            New: func() interface{} {
                return &PlayerUpdate{}
            },
        },
        
        packetPool: sync.Pool{
            New: func() interface{} {
                buf := make([]byte, 1500) // MTU
                return &buf
            },
        },
    }
}

// 뤯햑햊햎햊행햃햕햊햞: Adaptive tick rate
func (s *GameServer) AdaptTickRate() {
    count := s.playerCount.Load()
    
    switch {
    case count < 50:
        s.tickRate = 8 * time.Millisecond   // 128 Hz
    case count < 200:
        s.tickRate = 16 * time.Millisecond  // 60 Hz
    case count < 500:
        s.tickRate = 33 * time.Millisecond  // 30 Hz
    default:
        s.tickRate = 50 * time.Millisecond  // 20 Hz
    }
}

// Game loop
func (s *GameServer) Run(ctx context.Context) {
    ticker := time.NewTicker(s.tickRate)
    defer ticker.Stop()
    
    for {
        select {
        case <-ctx.Done():
            return
        case <-ticker.C:
            s.Update()
            s.AdaptTickRate()
            ticker.Reset(s.tickRate)
        }
    }
}

// 뤯햑햊햎햊행햃햕햊햞: Spatial partitioning 햢햩혪 broadcast
func (s *GameServer) BroadcastUpdate(player *Player, update []byte) {
    // 햑쮏혧햨 햦햡쮏쥃썛  햟햢햦혞혜햣
    nearby := s.spatialGrid.GetNearbyPlayers(player.Position, 100.0)
    
    // 뤯햑햊햎햊행햃햕햊햞: Worker pool 햢햩혪 parallel send
    for _, p := range nearby {
        p := p // Capture
        s.workerPool.Submit(func() {
            p.SendUpdate(update)
        })
    }
}
```

## 游깷 spatial_grid.go

```go
// Issue: #123
package server

import "sync"

type CellID struct {
    X, Y int32
}

type Cell struct {
    mu      sync.RWMutex
    players map[uint64]*Player
}

type SpatialGrid struct {
    cellSize float32
    cells    sync.Map // Lock-free map
}

func NewSpatialGrid(cellSize float32) *SpatialGrid {
    return &SpatialGrid{
        cellSize: cellSize,
    }
}

func (g *SpatialGrid) GetCell(pos Vector3) CellID {
    return CellID{
        X: int32(pos.X / g.cellSize),
        Y: int32(pos.Z / g.cellSize), // XZ plane
    }
}

func (g *SpatialGrid) AddPlayer(player *Player) {
    cellID := g.GetCell(player.Position)
    
    cellInterface, _ := g.cells.LoadOrStore(cellID, &Cell{
        players: make(map[uint64]*Player),
    })
    cell := cellInterface.(*Cell)
    
    cell.mu.Lock()
    cell.players[player.ID] = player
    cell.mu.Unlock()
}

func (g *SpatialGrid) RemovePlayer(player *Player) {
    cellID := g.GetCell(player.Position)
    
    if cellInterface, ok := g.cells.Load(cellID); ok {
        cell := cellInterface.(*Cell)
        
        cell.mu.Lock()
        delete(cell.players, player.ID)
        cell.mu.Unlock()
    }
}

// 뤯햑햊햎햊행햃햕햊햞: 쮏혞혢햦혝혧 햦햡쮏쥃쮏 혝쮏혧햨  햟햢햦혞혜햣
func (g *SpatialGrid) GetNearbyPlayers(pos Vector3, radius float32) []*Player {
    cellID := g.GetCell(pos)
    cellRadius := int32(radius / g.cellSize)
    
    // 뤯햑햊햎햊행햃햕햊햞: Preallocation (햦햪햣햫)
    nearby := make([]*Player, 0, 64)
    
    // Check surrounding cells
    for x := cellID.X - cellRadius; x <= cellID.X + cellRadius; x++ {
        for y := cellID.Y - cellRadius; y <= cellID.Y + cellRadius; y++ {
            if cellInterface, ok := g.cells.Load(CellID{X: x, Y: y}); ok {
                cell := cellInterface.(*Cell)
                
                cell.mu.RLock()
                for _, player := range cell.players {
                    // Check exact distance
                    distSq := pos.DistanceSquared(player.Position)
                    if distSq <= radius*radius {
                        nearby = append(nearby, player)
                    }
                }
                cell.mu.RUnlock()
            }
        }
    }
    
    return nearby
}
```

## 游니 udp_server.go

```go
// Issue: #123
package server

import (
    "net"
    "runtime"
    "sync"
)

// 뤯햑햊햎햊행햃햕햊햞: Buffer pool 햢햩혪 UDP packets
var udpBufferPool = sync.Pool{
    New: func() interface{} {
        buf := make([]byte, 1500) // MTU size
        return &buf
    },
}

type UDPServer struct {
    conn   *net.UDPConn
    router *PacketRouter
}

func NewUDPServer(addr string) (*UDPServer, error) {
    udpAddr, err := net.ResolveUDPAddr("udp", addr)
    if err != nil {
        return nil, err
    }
    
    conn, err := net.ListenUDP("udp", udpAddr)
    if err != nil {
        return nil, err
    }
    
    // 뤯햑햊햎햊행햃햕햊햞: Set buffer sizes
    conn.SetReadBuffer(4 * 1024 * 1024)  // 4MB
    conn.SetWriteBuffer(4 * 1024 * 1024) // 4MB
    
    return &UDPServer{
        conn:   conn,
        router: NewPacketRouter(),
    }, nil
}

func (s *UDPServer) Start() {
    // 뤯햑햊햎햊행햃햕햊햞: Multiple readers 햢햩혪 throughput
    for i := 0; i < runtime.NumCPU(); i++ {
        go s.readLoop()
    }
}

func (s *UDPServer) readLoop() {
    for {
        // 뤯햑햊햎햊행햃햕햊햞: Get buffer from pool
        bufPtr := udpBufferPool.Get().(*[]byte)
        buf := *bufPtr
        
        n, addr, err := s.conn.ReadFromUDP(buf)
        if err != nil {
            udpBufferPool.Put(bufPtr)
            continue
        }
        
        // Process packet (don't block!)
        go func(data []byte, addr *net.UDPAddr) {
            defer udpBufferPool.Put(bufPtr)
            s.router.Route(data[:n], addr)
        }(buf, addr)
    }
}

// 뤯햑햊햎햊행햃햕햊햞: Batch send
func (s *UDPServer) SendBatch(updates []PlayerUpdate, addrs []*net.UDPAddr) {
    batch := make([]byte, 0, 64*1024) // 64KB buffer
    
    for i, update := range updates {
        // Serialize update
        data := update.Marshal()
        batch = append(batch, data...)
        
        // Flush before MTU or end
        if len(batch) > 60000 || i == len(updates)-1 {
            s.conn.WriteToUDP(batch, addrs[i])
            batch = batch[:0]
        }
    }
}
```

## 햐햪. 혝햟햨햤햣

- `.cursor/templates/backend-api-templates.md` - API handlers/service/repository
- `.cursor/templates/backend-utils-templates.md` - utilities 햦 tests

