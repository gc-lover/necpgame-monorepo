databaseChangeLog:
- changeSet:
    id: documentation-quest-004-presidio-ai-research-ethics-c12fab4c
    author: content-migration-generator
    changes:
    - insert:
        tableName: project.documentation
        columns:
        - column:
            name: id
            value: '5830223995915278'
        - column:
            name: doc_id
            value: quest-san-francisco-2020-2029-presidio-ai-research-ethics
        - column:
            name: title
            value: San Francisco 2020-2029 — Этика исследований ИИ в Пресидио
        - column:
            name: document_type
            value: canon
        - column:
            name: category
            value: quests
        - column:
            name: status
            value: draft
        - column:
            name: version
            value: 1.0.0
        - column:
            name: last_updated
            value: 2025-12-23 18:31:00+00:00
        - column:
            name: concept_approved
            value: false
        - column:
            name: concept_reviewed_at
            value: ''
        - column:
            name: owners
            value: '[{"role": "content_writer", "contact": "content@necp.game"}]'
        - column:
            name: tags
            value:
            - san-francisco
            - presidio-ai-research-ethics
            - ai-ethical-frameworks
            - military-ai-development
            - research-center-oversight
        - column:
            name: topics
            value:
            - presidio_ai_research_ethics_development
            - ai_ethical_frameworks_establishment
            - military_ai_development_control
            - research_center_oversight_systems
            - ai_safety_research_priorities
        - column:
            name: related_systems
            value:
            - narrative-service
            - quest-service
            - character-service
            - ai-service
        - column:
            name: related_documents
            value: '[{"id": "lore-presidio-ai-research-san-francisco", "relation":
              "references"}]'
        - column:
            name: source
            value: ''
        - column:
            name: visibility
            value: internal
        - column:
            name: audience
            value:
            - concept
            - narrative
            - liveops
        - column:
            name: risk_level
            value: critical
        - column:
            name: content
            value: '{"metadata": {"id": "quest-san-francisco-2020-2029-presidio-ai-research-ethics",
              "title": "San Francisco 2020-2029 — Этика исследований ИИ в Пресидио",
              "document_type": "canon", "category": "quests", "status": "draft", "version":
              "1.0.0", "last_updated": "2025-12-23T18:31:00+00:00", "concept_approved":
              false, "concept_reviewed_at": "", "owners": [{"role": "content_writer",
              "contact": "content@necp.game"}], "tags": ["san-francisco", "presidio-ai-research-ethics",
              "ai-ethical-frameworks", "military-ai-development", "research-center-oversight"],
              "topics": ["presidio_ai_research_ethics_development", "ai_ethical_frameworks_establishment",
              "military_ai_development_control", "research_center_oversight_systems",
              "ai_safety_research_priorities"], "related_systems": ["narrative-service",
              "quest-service", "character-service", "ai-service"], "related_documents":
              [{"id": "lore-presidio-ai-research-san-francisco", "relation": "references"}],
              "source": "", "visibility": "internal", "audience": ["concept", "narrative",
              "liveops"], "risk_level": "critical"}, "review": {"chain": [{"role":
              "content_director", "reviewer": "", "reviewed_at": "", "status": "pending"}],
              "next_actions": []}, "summary": {"problem": "В 2020-2029-х Пресидио,
              бывшая военная база в Сан-Франциско, становится\nцентром этических исследований
              ИИ. Правительство финансирует разработку\n\"безопасного ИИ\" для военных
              целей, но возникают вопросы о том, насколько\nэтично создавать ИИ для
              войны, кто контролирует исследования и что произойдет,\nесли \"безопасный
              ИИ\" выйдет из-под контроля. Возникает вопрос: может ли\nчеловечество
              создать ИИ, который будет одновременно мощным и этичным,\nили стремление
              к безопасности лишь маскирует жажду власти?\n", "goal": "Участвовать
              в этических исследованиях ИИ в Пресидио, помочь разработать\nэтические
              рамки для ИИ, обеспечить безопасность и ответственность.\n", "essence":
              "Квест исследует природу контроля: может ли человечество контролировать\nсозданное
              им сверхразумное существо, или все попытки создать \"безопасный ИИ\"\nобречены
              на провал из-за фундаментального непонимания природы интеллекта?\nВ
              мире, где ИИ может переписать реальность, кто решает, что такое \"безопасно\"?\n",
              "key_points": ["Разработка этических рамок для ИИ", "Исследования безопасности
              ИИ", "Решение вопросов военного применения ИИ", "Создание систем контроля
              и надзора"]}, "quest_definition": {"quest_type": "main", "level_min":
              50, "level_max": 60, "requirements": {"required_quests": [], "required_flags":
              ["san-francisco_access", "ai_researcher"], "required_reputation": {},
              "required_items": []}, "objectives": [{"id": "establish_ai_ethical_framework",
              "text": "Установить этические рамки ИИ", "type": "establish", "target":
              "ai_development_principles", "count": 1, "optional": false}, {"id":
              "develop_safety_research_protocols", "text": "Разработать протоколы
              исследований безопасности", "type": "develop", "target": "ai_containment_strategies",
              "count": 2, "optional": false}, {"id": "address_military_ai_concerns",
              "text": "Решить вопросы военного ИИ", "type": "address", "target": "dual_use_technology_ethics",
              "count": 3, "optional": false}, {"id": "create_oversight_mechanisms",
              "text": "Создать механизмы надзора", "type": "create", "target": "research_transparency_systems",
              "count": 1, "optional": false}, {"id": "implement_responsible_ai_practices",
              "text": "Внедрить ответственные практики ИИ", "type": "implement", "target":
              "ethical_ai_development_standards", "count": 2, "optional": false}],
              "rewards": [{"experience": 11600}, {"credits": 27500}, {"reputation":
              {"factions": {"ai_safety_researchers": 70, "ethical_ai_advocates": 65,
              "military_responsibility_officers": 60}}}, {"items": ["ai_ethics_analysis_tool",
              "safety_research_protocols", "oversight_monitoring_device"]}, {"unlocks":
              ["quest_ai_ethics_chain", "ai_safety_research_skills", "ethical_framework_training"]}],
              "branches": [{"condition": "establish_global_ai_standards", "next_quest":
              "international_ai_governance"}, {"condition": "focus_on_military_applications",
              "next_quest": "responsible_military_ai"}, {"condition": "fail_containment_strategies",
              "next_quest": "ai_existential_risk"}]}, "content": {"sections": [{"id":
              "introduction", "title": "Введение", "body": "Сан-Франциско 2020-2029-х.
              Пресидио, парк на месте бывшей военной базы,\nстановится центром исследований
              этики ИИ. \"Мы создадим безопасный ИИ,\"\n— обещают ученые. \"Мы выпустим
              джинна из бутылки,\" — предупреждают\nфилософы. В бункерах и лабораториях
              рождаются вопросы, на которые\nчеловечество еще не знает ответов.\n"},
              {"id": "ai_ethical_frameworks", "title": "Этические рамки ИИ", "body":
              "Что такое \"добро\" для ИИ? Как определить \"безопасность\"? Кто принимает\nрешения?
              \"Мы запрограммируем этику,\" — говорят инженеры. \"Этика не\nпрограммируется,\"
              — отвечают философы. Центр становится полем битвы\nидей.\n"}, {"id":
              "military_ai_development", "title": "Разработка военного ИИ", "body":
              "ИИ для разведки, тактики, автономного оружия — разработки обещают\nпреимущество
              в войне. \"Это спасет жизни,\" — говорят военные. \"Это\nначнет войну
              машин,\" — обвиняют пацифисты. Этика встречается с\nнеобходимостью.\n"},
              {"id": "research_center_oversight", "title": "Надзор центра исследований",
              "body": "Кто контролирует исследования? Какие секреты хранятся? Как
              предотвратить\nзлоупотребления? \"Прозрачность максимальна,\" — обещают
              власти. \"Секреты\nнеизбежны,\" — отвечают реалисты. Доверие становится
              главным активом.\n"}, {"id": "ai_safety_research_priorities", "title":
              "Приоритеты исследований безопасности ИИ", "body": "Контейнеры, kill
              switches, alignment problems — безопасность становится\nнаукой. \"Мы
              решим все проблемы,\" — уверяют оптимисты. \"Мы создаем\nновые,\" —
              предупреждают скептики. Исследования становятся гонкой\nс самими собой.\n"},
              {"id": "ai_research_ethics_future_decision", "title": "Решение по будущему
              этики исследований ИИ", "body": "В конференц-зале Пресидио, окруженный
              голографическими симуляциями\nИИ-сценариев и потоками исследовательских
              данных, вы должны выбрать\nпуть развития этики ИИ: установить глобальные
              стандарты безопасности\nдля всего человечества; сосредоточиться на этичных
              военных приложениях;\nили признать фундаментальную невозможность контроля
              ИИ.\n"}]}, "appendix": {"glossary": [{"presidio-ai-research": "исследования
              ИИ в Пресидио"}, {"ai-ethical-frameworks": "этические рамки ИИ"}, {"military-ai-development":
              "разработка военного ИИ"}], "references": [], "decisions": ["control_vs_freedom",
              "safety_vs_capability", "ethics_vs_necessity"]}, "implementation": {"github_issue":
              "#140890388", "needs_task": false, "queue_reference": [], "blockers":
              []}, "history": [{"version": "1.0.0", "date": "2025-12-23", "author":
              "content_writer", "changes": "Создан квест об Этике исследований ИИ
              в Пресидио в Сан-Франциско 2020-2029-х."}], "validation": {"checksum":
              "", "schema_version": "1.0"}}'
        - column:
            name: metadata
            value: '{"id": "quest-san-francisco-2020-2029-presidio-ai-research-ethics",
              "title": "San Francisco 2020-2029 — Этика исследований ИИ в Пресидио",
              "document_type": "canon", "category": "quests", "status": "draft", "version":
              "1.0.0", "last_updated": "2025-12-23T18:31:00+00:00", "concept_approved":
              false, "concept_reviewed_at": "", "owners": [{"role": "content_writer",
              "contact": "content@necp.game"}], "tags": ["san-francisco", "presidio-ai-research-ethics",
              "ai-ethical-frameworks", "military-ai-development", "research-center-oversight"],
              "topics": ["presidio_ai_research_ethics_development", "ai_ethical_frameworks_establishment",
              "military_ai_development_control", "research_center_oversight_systems",
              "ai_safety_research_priorities"], "related_systems": ["narrative-service",
              "quest-service", "character-service", "ai-service"], "related_documents":
              [{"id": "lore-presidio-ai-research-san-francisco", "relation": "references"}],
              "source": "", "visibility": "internal", "audience": ["concept", "narrative",
              "liveops"], "risk_level": "critical"}'
        - column:
            name: source_file
            value: knowledge\canon\lore\timeline-author\quests\america\san-francisco\2020-2029\quest-004-presidio-ai-research-ethics.yaml
