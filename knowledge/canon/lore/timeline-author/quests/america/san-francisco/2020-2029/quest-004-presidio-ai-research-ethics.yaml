metadata:
  id: quest-san-francisco-2020-2029-presidio-ai-research-ethics
  title: 'San Francisco 2020-2029 — Этика исследований ИИ в Пресидио'
  document_type: canon
  category: quests
  status: draft
  version: '1.0.0'
  last_updated: 2025-12-23T18:31:00Z
  concept_approved: false
  concept_reviewed_at: ''
  owners:
    - role: content_writer
      contact: content@necp.game
  tags:
    - san-francisco
    - presidio-ai-research-ethics
    - ai-ethical-frameworks
    - military-ai-development
    - research-center-oversight
  topics:
    - presidio_ai_research_ethics_development
    - ai_ethical_frameworks_establishment
    - military_ai_development_control
    - research_center_oversight_systems
    - ai_safety_research_priorities
  related_systems:
    - narrative-service
    - quest-service
    - character-service
    - ai-service
  related_documents:
    - id: lore-presidio-ai-research-san-francisco
      relation: references
  source: ''
  visibility: internal
  audience:
    - concept
    - narrative
    - liveops
  risk_level: critical

review:
  chain:
    - role: content_director
      reviewer: ''
      reviewed_at: ''
      status: pending
  next_actions: [ ]

summary:
  problem: |
    В 2020-2029-х Пресидио, бывшая военная база в Сан-Франциско, становится
    центром этических исследований ИИ. Правительство финансирует разработку
    "безопасного ИИ" для военных целей, но возникают вопросы о том, насколько
    этично создавать ИИ для войны, кто контролирует исследования и что произойдет,
    если "безопасный ИИ" выйдет из-под контроля. Возникает вопрос: может ли
    человечество создать ИИ, который будет одновременно мощным и этичным,
    или стремление к безопасности лишь маскирует жажду власти?
  goal: |
    Участвовать в этических исследованиях ИИ в Пресидио, помочь разработать
    этические рамки для ИИ, обеспечить безопасность и ответственность.
  essence: |
    Квест исследует природу контроля: может ли человечество контролировать
    созданное им сверхразумное существо, или все попытки создать "безопасный ИИ"
    обречены на провал из-за фундаментального непонимания природы интеллекта?
    В мире, где ИИ может переписать реальность, кто решает, что такое "безопасно"?
  key_points:
    - Разработка этических рамок для ИИ
    - Исследования безопасности ИИ
    - Решение вопросов военного применения ИИ
    - Создание систем контроля и надзора

quest_definition:
  quest_type: main
  level_min: 50
  level_max: 60
  requirements:
    required_quests: [ ]
    required_flags:
      - san-francisco_access
      - ai_researcher
    required_reputation: { }
    required_items: [ ]
  objectives:
    - id: establish_ai_ethical_framework
      text: "Установить этические рамки ИИ"
      type: establish
      target: ai_development_principles
      count: 1
      optional: false
    - id: develop_safety_research_protocols
      text: "Разработать протоколы исследований безопасности"
      type: develop
      target: ai_containment_strategies
      count: 2
      optional: false
    - id: address_military_ai_concerns
      text: "Решить вопросы военного ИИ"
      type: address
      target: dual_use_technology_ethics
      count: 3
      optional: false
    - id: create_oversight_mechanisms
      text: "Создать механизмы надзора"
      type: create
      target: research_transparency_systems
      count: 1
      optional: false
    - id: implement_responsible_ai_practices
      text: "Внедрить ответственные практики ИИ"
      type: implement
      target: ethical_ai_development_standards
      count: 2
      optional: false
  rewards:
    - experience: 11600
    - credits: 27500
    - reputation:
        factions:
          ai_safety_researchers: 70
          ethical_ai_advocates: 65
          military_responsibility_officers: 60
    - items:
        - ai_ethics_analysis_tool
        - safety_research_protocols
        - oversight_monitoring_device
    - unlocks:
        - quest_ai_ethics_chain
        - ai_safety_research_skills
        - ethical_framework_training
  branches:
    - condition: establish_global_ai_standards
      next_quest: international_ai_governance
    - condition: focus_on_military_applications
      next_quest: responsible_military_ai
    - condition: fail_containment_strategies
      next_quest: ai_existential_risk

content:
  sections:
    - id: introduction
      title: 'Введение'
      body: |
        Сан-Франциско 2020-2029-х. Пресидио, парк на месте бывшей военной базы,
        становится центром исследований этики ИИ. "Мы создадим безопасный ИИ,"
        — обещают ученые. "Мы выпустим джинна из бутылки," — предупреждают
        философы. В бункерах и лабораториях рождаются вопросы, на которые
        человечество еще не знает ответов.
    - id: ai_ethical_frameworks
      title: 'Этические рамки ИИ'
      body: |
        Что такое "добро" для ИИ? Как определить "безопасность"? Кто принимает
        решения? "Мы запрограммируем этику," — говорят инженеры. "Этика не
        программируется," — отвечают философы. Центр становится полем битвы
        идей.
    - id: military_ai_development
      title: 'Разработка военного ИИ'
      body: |
        ИИ для разведки, тактики, автономного оружия — разработки обещают
        преимущество в войне. "Это спасет жизни," — говорят военные. "Это
        начнет войну машин," — обвиняют пацифисты. Этика встречается с
        необходимостью.
    - id: research_center_oversight
      title: 'Надзор центра исследований'
      body: |
        Кто контролирует исследования? Какие секреты хранятся? Как предотвратить
        злоупотребления? "Прозрачность максимальна," — обещают власти. "Секреты
        неизбежны," — отвечают реалисты. Доверие становится главным активом.
    - id: ai_safety_research_priorities
      title: 'Приоритеты исследований безопасности ИИ'
      body: |
        Контейнеры, kill switches, alignment problems — безопасность становится
        наукой. "Мы решим все проблемы," — уверяют оптимисты. "Мы создаем
        новые," — предупреждают скептики. Исследования становятся гонкой
        с самими собой.
    - id: ai_research_ethics_future_decision
      title: 'Решение по будущему этики исследований ИИ'
      body: |
        В конференц-зале Пресидио, окруженный голографическими симуляциями
        ИИ-сценариев и потоками исследовательских данных, вы должны выбрать
        путь развития этики ИИ: установить глобальные стандарты безопасности
        для всего человечества; сосредоточиться на этичных военных приложениях;
        или признать фундаментальную невозможность контроля ИИ.

appendix:
  glossary:
    - presidio-ai-research: исследования ИИ в Пресидио
    - ai-ethical-frameworks: этические рамки ИИ
    - military-ai-development: разработка военного ИИ
  references: [ ]
  decisions:
    - control_vs_freedom
    - safety_vs_capability
    - ethics_vs_necessity
implementation:
  github_issue: '#140890388'
  needs_task: false
  queue_reference: [ ]
  blockers: [ ]
history:
  - version: '1.0.0'
    date: 2025-12-23
    author: content_writer
    changes: 'Создан квест об Этике исследований ИИ в Пресидио в Сан-Франциско 2020-2029-х.'
validation:
  checksum: ''
  schema_version: '1.0'
