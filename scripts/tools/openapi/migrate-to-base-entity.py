#!/usr/bin/env python3
"""
–°–∫—Ä–∏–ø—Ç –º–∏–≥—Ä–∞—Ü–∏–∏ —Å—É—â–Ω–æ—Å—Ç–µ–π –Ω–∞ BASE-ENTITY —Å–∏—Å—Ç–µ–º—É.

–¶–µ–ª—å: –ó–∞–º–µ–Ω–∏—Ç—å –¥—É–±–ª–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –ø–æ–ª—è –≤ —Å—É—â–Ω–æ—Å—Ç—è—Ö –Ω–∞ allOf –∫–æ–º–ø–æ–∑–∏—Ü–∏—é —Å BASE-ENTITY.

–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ:
    python scripts/openapi/migrate-to-base-entity.py proto/openapi/social-domain/schemas/entities/guild.yaml --dry-run
    python scripts/openapi/migrate-to-base-entity.py proto/openapi/social-domain/ --all-entities --execute
"""

import os
import yaml
import argparse
from pathlib import Path
from typing import Dict, List, Set, Tuple, Optional
from collections import defaultdict
import re

class BaseEntityMigrator:
    """–ú–∏–≥—Ä–∞—Ç–æ—Ä —Å—É—â–Ω–æ—Å—Ç–µ–π –Ω–∞ BASE-ENTITY —Å–∏—Å—Ç–µ–º—É."""

    # BASE-ENTITY –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –±—É–¥—É—Ç –∑–∞–≥—Ä—É–∂–∞—Ç—å—Å—è –∏–∑ common-schemas.yaml

    def __init__(self, common_schemas_path: Optional[str] = None, dry_run: bool = True):
        if common_schemas_path:
            self.common_schemas_path = Path(common_schemas_path)
        else:
            # –ò—â–µ–º common-schemas.yaml –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–æ –∫–æ—Ä–Ω—è –ø—Ä–æ–µ–∫—Ç–∞
            script_dir = Path(__file__).parent.parent.parent  # scripts/openapi/ -> scripts/ -> root
            possible_paths = [
                script_dir / "proto" / "openapi" / "common-schemas.yaml",
                script_dir / "common-schemas.yaml",
                Path("proto/openapi/common-schemas.yaml"),
                Path("common-schemas.yaml"),
            ]
            for path in possible_paths:
                if path.exists():
                    self.common_schemas_path = path
                    break
            else:
                self.common_schemas_path = script_dir / "proto" / "openapi" / "common-schemas.yaml"

        self.dry_run = dry_run
        self.stats = {
            'entities_processed': 0,
            'entities_migrated': 0,
            'fields_removed': 0,
            'errors': []
        }

        # –ó–∞–≥—Ä—É–∑–∫–∞ BASE-ENTITY –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–π
        self.base_entities = self._load_base_entities()

    def _load_base_entities(self) -> Dict[str, Set[str]]:
        """–ó–∞–≥—Ä—É–∑–∫–∞ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–π BASE-ENTITY –∏–∑ common-schemas.yaml."""
        if not self.common_schemas_path.exists():
            print(f"[WARNING] common-schemas.yaml not found: {self.common_schemas_path}")
            return {}  # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –ø—É—Å—Ç–æ–π —Å–ª–æ–≤–∞—Ä—å –≤–º–µ—Å—Ç–æ –∂–µ—Å—Ç–∫–æ –∑–∞–¥–∞–Ω–Ω—ã—Ö

        try:
            with open(self.common_schemas_path, 'r', encoding='utf-8') as f:
                content = yaml.safe_load(f)

            schemas = content.get('components', {}).get('schemas', {})
            loaded_entities = {}

            for schema_name, schema_def in schemas.items():
                if isinstance(schema_def, dict):
                    # –°–æ–±–∏—Ä–∞–µ–º –≤—Å–µ –ø–æ–ª—è –∏–∑ —Å—Ö–µ–º—ã, –≤–∫–ª—é—á–∞—è –≤–ª–æ–∂–µ–Ω–Ω—ã–µ allOf
                    all_fields = set()
                    self._extract_all_fields(schema_def, schemas, all_fields)
                    if all_fields:  # –¢–æ–ª—å–∫–æ –µ—Å–ª–∏ –µ—Å—Ç—å –ø–æ–ª—è
                        loaded_entities[schema_name] = all_fields

            print(f"[OK] Loaded {len(loaded_entities)} BASE-ENTITY definitions from {self.common_schemas_path}")
            return loaded_entities

        except Exception as e:
            print(f"[WARNING] Error loading BASE-ENTITY: {e}")
            return {}

    def _extract_all_fields(self, schema_def: dict, all_schemas: dict, fields: set, visited: set = None) -> None:
        """–†–µ–∫—É—Ä—Å–∏–≤–Ω–æ –∏–∑–≤–ª–µ–∫–∞–µ—Ç –≤—Å–µ –ø–æ–ª—è –∏–∑ —Å—Ö–µ–º—ã, –≤–∫–ª—é—á–∞—è allOf –∫–æ–º–ø–æ–∑–∏—Ü–∏—é."""
        if visited is None:
            visited = set()

        # –ò–∑–±–µ–≥–∞–µ–º —Ü–∏–∫–ª–∏—á–µ—Å–∫–∏—Ö —Å—Å—ã–ª–æ–∫
        schema_id = id(schema_def)
        if schema_id in visited:
            return
        visited.add(schema_id)

        # –ü—Ä—è–º—ã–µ properties
        if 'properties' in schema_def:
            fields.update(schema_def['properties'].keys())

        # allOf –∫–æ–º–ø–æ–∑–∏—Ü–∏—è
        if 'allOf' in schema_def:
            for item in schema_def['allOf']:
                if isinstance(item, dict):
                    if '$ref' in item:
                        # –†–∞–∑—Ä–µ—à–∞–µ–º —Å—Å—ã–ª–∫—É
                        ref = item['$ref']
                        if ref.startswith('#/components/schemas/'):
                            ref_name = ref.split('#/components/schemas/')[1]
                            if ref_name in all_schemas:
                                self._extract_all_fields(all_schemas[ref_name], all_schemas, fields, visited)
                    else:
                        # –í—Å—Ç—Ä–æ–µ–Ω–Ω–∞—è —Å—Ö–µ–º–∞
                        self._extract_all_fields(item, all_schemas, fields, visited)

    def migrate_entity_file(self, file_path: str) -> Optional[Dict]:
        """–ú–∏–≥—Ä–∞—Ü–∏—è –æ–¥–Ω–æ–≥–æ —Ñ–∞–π–ª–∞ —Å—É—â–Ω–æ—Å—Ç–∏."""
        file_path = Path(file_path)

        if not file_path.exists():
            raise FileNotFoundError(f"–§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {file_path}")

        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = yaml.safe_load(f)

            # –ù–∞—Ö–æ–¥–∏–º –≤—Å–µ —Å—Ö–µ–º—ã –≤ —Ñ–∞–π–ª–µ
            migrated_schemas = {}

            if 'components' in content and 'schemas' in content['components']:
                for schema_name, schema_def in content['components']['schemas'].items():
                    migrated_schema = self._migrate_single_entity(schema_name, schema_def)
                    if migrated_schema:
                        migrated_schemas[schema_name] = migrated_schema
                        self.stats['entities_migrated'] += 1

            self.stats['entities_processed'] += len(content.get('components', {}).get('schemas', {}))

            # –°–æ–∑–¥–∞–Ω–∏–µ –Ω–æ–≤–æ–≥–æ —Å–æ–¥–µ—Ä–∂–∏–º–æ–≥–æ —Ñ–∞–π–ª–∞
            if migrated_schemas:
                new_content = content.copy()
                new_content['components']['schemas'] = migrated_schemas

                if not self.dry_run:
                    with open(file_path, 'w', encoding='utf-8') as f:
                        yaml.dump(new_content, f, default_flow_style=False, allow_unicode=True)

                return {
                    'file': str(file_path),
                    'migrated_entities': list(migrated_schemas.keys()),
                    'total_entities': len(content.get('components', {}).get('schemas', {}))
                }

        except Exception as e:
            self.stats['errors'].append(f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ {file_path}: {e}")
            return None

    def _migrate_single_entity(self, entity_name: str, schema_def: Dict) -> Optional[Dict]:
        """–ú–∏–≥—Ä–∞—Ü–∏—è –æ–¥–Ω–æ–π —Å—É—â–Ω–æ—Å—Ç–∏ –Ω–∞ BASE-ENTITY."""
        if not isinstance(schema_def, dict) or 'properties' not in schema_def:
            return None

        entity_fields = set(schema_def['properties'].keys())

        # –ù–∞—Ö–æ–¥–∏–º –ª—É—á—à–∏–π BASE-ENTITY –¥–ª—è —ç—Ç–æ–π —Å—É—â–Ω–æ—Å—Ç–∏
        best_base_entity, matching_fields = self._find_best_base_entity(entity_fields)

        if not best_base_entity or not matching_fields:
            return None  # –ù–µ –Ω–∞–π–¥–µ–Ω–æ –ø–æ–¥—Ö–æ–¥—è—â–µ–≥–æ BASE-ENTITY

        # –í—ã—á–∏—Å–ª—è–µ–º –ø–æ–ª—è, –∫–æ—Ç–æ—Ä—ã–µ –æ—Å—Ç–∞–Ω—É—Ç—Å—è –≤ —Å—É—â–Ω–æ—Å—Ç–∏
        remaining_fields = entity_fields - matching_fields

        if not remaining_fields:
            return None  # –í—Å–µ –ø–æ–ª—è –ø–æ–∫—Ä—ã—Ç—ã BASE-ENTITY, –Ω–æ –¥–æ–ª–∂–Ω–∞ –æ—Å—Ç–∞—Ç—å—Å—è —Ö–æ—Ç—è –±—ã 1 —É–Ω–∏–∫–∞–ª—å–Ω–æ–µ –ø–æ–ª–µ

        # –°–æ–∑–¥–∞–µ–º –Ω–æ–≤—É—é —Å—Ö–µ–º—É —Å allOf
        new_schema = schema_def.copy()

        # –î–æ–±–∞–≤–ª—è–µ–º allOf –∫–æ–º–ø–æ–∑–∏—Ü–∏—é
        new_schema['allOf'] = [
            {
                '$ref': f'../../common-schemas.yaml#/components/schemas/{best_base_entity}'
            },
            {
                'type': 'object',
                'properties': {field: schema_def['properties'][field] for field in remaining_fields}
            }
        ]

        # –£–¥–∞–ª—è–µ–º —Å—Ç–∞—Ä—ã–µ properties (–æ–Ω–∏ —Ç–µ–ø–µ—Ä—å –≤ allOf)
        del new_schema['properties']

        # –û–±–Ω–æ–≤–ª—è–µ–º required –ø–æ–ª—è (—É–±–∏—Ä–∞–µ–º —Ç–µ, —á—Ç–æ —Ç–µ–ø–µ—Ä—å –≤ BASE-ENTITY)
        if 'required' in new_schema:
            base_entity_fields = self.base_entities.get(best_base_entity, set())
            new_required = [field for field in new_schema['required'] if field not in base_entity_fields]
            if new_required:
                new_schema['required'] = new_required
            else:
                del new_schema['required']

        # –û–±–Ω–æ–≤–ª—è–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
        self.stats['fields_removed'] += len(matching_fields)

        return new_schema

    def _find_best_base_entity(self, entity_fields: Set[str]) -> Tuple[Optional[str], Optional[Set[str]]]:
        """–ü–æ–∏—Å–∫ –ª—É—á—à–µ–≥–æ BASE-ENTITY –¥–ª—è –Ω–∞–±–æ—Ä–∞ –ø–æ–ª–µ–π."""
        best_match = None
        best_matching_fields = set()
        max_matching_count = 0

        for base_entity, base_fields in self.base_entities.items():
            matching_fields = entity_fields.intersection(base_fields)

            # –õ—É—á—à–∏–π –º–∞—Ç—á - –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–æ–≤–ø–∞–¥–∞—é—â–∏—Ö –ø–æ–ª–µ–π
            # –ù–æ —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ —Å–æ–≤–ø–∞–¥–∞–µ—Ç –±–æ–ª—å—à–µ 50% –ø–æ–ª–µ–π BASE-ENTITY
            if len(matching_fields) > max_matching_count and len(matching_fields) >= len(base_fields) * 0.5:
                max_matching_count = len(matching_fields)
                best_match = base_entity
                best_matching_fields = matching_fields

        return best_match, best_matching_fields

    def migrate_domain_entities(self, domain_path: str) -> List[Dict]:
        """–ú–∏–≥—Ä–∞—Ü–∏—è –≤—Å–µ—Ö —Å—É—â–Ω–æ—Å—Ç–µ–π –≤ –¥–æ–º–µ–Ω–µ."""
        domain_path = Path(domain_path)
        results = []

        # –ò—â–µ–º –≤—Å–µ —Ñ–∞–π–ª—ã —Å—É—â–Ω–æ—Å—Ç–µ–π
        entity_patterns = [
            '**/schemas/entities/*.yaml',
            '**/schemas/*.yaml',
            '**/*entity*.yaml',
            '**/*entities*.yaml'
        ]

        migrated_files = set()

        for pattern in entity_patterns:
            for entity_file in domain_path.glob(pattern):
                if entity_file in migrated_files:
                    continue

                result = self.migrate_entity_file(str(entity_file))
                if result:
                    results.append(result)
                    migrated_files.add(entity_file)

        return results

    def generate_report(self, results: List[Dict]) -> str:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç—á–µ—Ç–∞ –æ –º–∏–≥—Ä–∞—Ü–∏–∏."""
        report = []
        report.append("# üìä –û–¢–ß–ï–¢ –ú–ò–ì–†–ê–¶–ò–ò –ù–ê BASE-ENTITY")
        report.append("")
        report.append(f"**–†–µ–∂–∏–º:** {'DRY RUN' if self.dry_run else 'EXECUTE'}")
        report.append("")

        report.append("## üìà –°–¢–ê–¢–ò–°–¢–ò–ö–ê –ú–ò–ì–†–ê–¶–ò–ò")
        report.append("")
        report.append(f"- **–°—É—â–Ω–æ—Å—Ç–µ–π –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ:** {self.stats['entities_processed']}")
        report.append(f"- **–°—É—â–Ω–æ—Å—Ç–µ–π –º–∏–≥—Ä–∏—Ä–æ–≤–∞–Ω–æ:** {self.stats['entities_migrated']}")
        report.append(f"- **–ü–æ–ª–µ–π —É–¥–∞–ª–µ–Ω–æ:** {self.stats['fields_removed']}")
        report.append(f"- **–§–∞–π–ª–æ–≤ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ:** {len(results)}")
        report.append(f"- **–û—à–∏–±–æ–∫:** {len(self.stats['errors'])}")
        report.append("")

        if results:
            report.append("## üìÅ –ú–ò–ì–†–ò–†–û–í–ê–ù–ù–´–ï –§–ê–ô–õ–´")
            report.append("")
            for result in results:
                report.append(f"### {result['file']}")
                report.append(f"- **–ú–∏–≥—Ä–∏—Ä–æ–≤–∞–Ω–æ —Å—É—â–Ω–æ—Å—Ç–µ–π:** {len(result['migrated_entities'])}")
                report.append(f"- **–í—Å–µ–≥–æ —Å—É—â–Ω–æ—Å—Ç–µ–π:** {result['total_entities']}")
                if result['migrated_entities']:
                    report.append(f"- **–°—É—â–Ω–æ—Å—Ç–∏:** {', '.join(result['migrated_entities'])}")
                report.append("")

        if self.stats['errors']:
            report.append("## ‚ùå –û–®–ò–ë–ö–ò")
            report.append("")
            for error in self.stats['errors'][:10]:
                report.append(f"- {error}")
            if len(self.stats['errors']) > 10:
                report.append(f"- ... –∏ –µ—â–µ {len(self.stats['errors']) - 10} –æ—à–∏–±–æ–∫")
            report.append("")

        # –≠—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç—å DRY
        if self.stats['entities_processed'] > 0:
            migration_rate = (self.stats['entities_migrated'] / self.stats['entities_processed']) * 100
            avg_fields_removed = self.stats['fields_removed'] / self.stats['entities_migrated'] if self.stats['entities_migrated'] > 0 else 0

            report.append("## üìä –≠–§–§–ï–ö–¢–ò–í–ù–û–°–¢–¨ DRY")
            report.append("")
            report.append(".1f")
            report.append(".1f")
            report.append("")

        report.append("## üí° –†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–ò")
        report.append("")
        if self.dry_run:
            report.append("1. **–ü—Ä–æ–≤–µ—Ä—å—Ç–µ –∏–∑–º–µ–Ω–µ–Ω–∏—è** –≤ DRY RUN —Ä–µ–∂–∏–º–µ")
            report.append("2. **–ò—Å–ø—Ä–∞–≤—å—Ç–µ –æ—à–∏–±–∫–∏** –≤ —Å–ø–∏—Å–∫–µ –≤—ã—à–µ")
            report.append("3. **–ó–∞–ø—É—Å—Ç–∏—Ç–µ —Å --execute** –¥–ª—è –ø—Ä–∏–º–µ–Ω–µ–Ω–∏—è –∏–∑–º–µ–Ω–µ–Ω–∏–π")
        else:
            report.append("1. **–ó–∞–ø—É—Å—Ç–∏—Ç–µ –≤–∞–ª–∏–¥–∞—Ü–∏—é:** `npx @redocly/cli lint`")
            report.append("2. **–ü—Ä–æ–≤–µ—Ä—å—Ç–µ –≥–µ–Ω–µ—Ä–∞—Ü–∏—é –∫–æ–¥–∞:** `ogen --target test-gen`")
            report.append("3. **–û–±–Ω–æ–≤–∏—Ç–µ —Ç–µ—Å—Ç—ã** –¥–ª—è –∏–∑–º–µ–Ω–µ–Ω–Ω—ã—Ö —Å—Ö–µ–º")
            report.append("4. **–°–æ–∑–¥–∞–π—Ç–µ backup** –¥–ª—è –æ—Ç–∫–∞—Ç–∞ –ø—Ä–∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏")

        return "\n".join(report)


def main():
    parser = argparse.ArgumentParser(description='–ú–∏–≥—Ä–∞—Ü–∏—è —Å—É—â–Ω–æ—Å—Ç–µ–π –Ω–∞ BASE-ENTITY —Å–∏—Å—Ç–µ–º—É')
    parser.add_argument('path', help='–ü—É—Ç—å –∫ —Ñ–∞–π–ª—É —Å—É—â–Ω–æ—Å—Ç–∏ –∏–ª–∏ –¥–æ–º–µ–Ω—É')
    parser.add_argument('--all-entities', action='store_true', help='–ú–∏–≥—Ä–∏—Ä–æ–≤–∞—Ç—å –≤—Å–µ —Å—É—â–Ω–æ—Å—Ç–∏ –≤ –¥–æ–º–µ–Ω–µ')
    parser.add_argument('--dry-run', action='store_true', help='–¢–æ–ª—å–∫–æ –∞–Ω–∞–ª–∏–∑, –±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π')
    parser.add_argument('--execute', action='store_true', help='–í—ã–ø–æ–ª–Ω–∏—Ç—å –º–∏–≥—Ä–∞—Ü–∏—é')
    parser.add_argument('--common-schemas', help='–ü—É—Ç—å –∫ common-schemas.yaml')
    parser.add_argument('--output', '-o', default='scripts/reports/base-entity-migration-report.md', help='–§–∞–π–ª –¥–ª—è –æ—Ç—á–µ—Ç–∞')

    args = parser.parse_args()

    if not (args.dry_run or args.execute):
        args.dry_run = True  # –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é dry-run

    migrator = BaseEntityMigrator(args.common_schemas, dry_run=args.dry_run)

    results = []

    if args.all_entities:
        # –ú–∏–≥—Ä–∞—Ü–∏—è –≤—Å–µ—Ö —Å—É—â–Ω–æ—Å—Ç–µ–π –≤ –¥–æ–º–µ–Ω–µ
        results = migrator.migrate_domain_entities(args.path)
    else:
        # –ú–∏–≥—Ä–∞—Ü–∏—è –æ–¥–Ω–æ–≥–æ —Ñ–∞–π–ª–∞
        result = migrator.migrate_entity_file(args.path)
        if result:
            results = [result]

    # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –æ—Ç—á–µ—Ç–∞
    report = migrator.generate_report(results)
    with open(args.output, 'w', encoding='utf-8') as f:
        f.write(report)

    print(f"[REPORT] Report saved to: {args.output}")

    # –í—ã–≤–æ–¥ –∫—Ä–∞—Ç–∫–æ–π —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
    print("\n[STATS] SUMMARY:")
    print(f"   Entities processed: {migrator.stats['entities_processed']}")
    print(f"   Entities migrated: {migrator.stats['entities_migrated']}")
    print(f"   Fields removed: {migrator.stats['fields_removed']}")
    if migrator.stats['errors']:
        print(f"   Errors: {len(migrator.stats['errors'])}")


if __name__ == '__main__':
    main()
