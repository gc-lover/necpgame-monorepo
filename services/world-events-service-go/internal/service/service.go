// Code generated by NECPGAME backend agent. Enterprise-grade World Events service.
// PERFORMANCE: Optimized for real-time world event scheduling and Kafka event processing
// Issue: #2224 - Реализация world-events-service-go

package service

import (
	"context"
	"encoding/json"
	"fmt"
	"math/rand"
	"strings"
	"sync"
	"time"

	"github.com/Shopify/sarama"
	"github.com/go-faster/errors"
	"github.com/google/uuid"
	"github.com/jackc/pgx/v5/pgxpool"
	"github.com/prometheus/client_golang/prometheus"
	"go.opentelemetry.io/otel/metric"
	"go.opentelemetry.io/otel/trace"
	"go.uber.org/zap"

	"necpgame/services/world-events-service-go/internal/models"
)

// PERFORMANCE: Memory pooling for hot path objects (Level 2 optimization)
// Reduces GC pressure in high-throughput world event processing
var (
	eventPool = sync.Pool{
		New: func() interface{} {
			return &models.WorldEvent{}
		},
	}

	participantPool = sync.Pool{
		New: func() interface{} {
			return &models.WorldEventParticipant{}
		},
	}
)

// Config holds service configuration
// PERFORMANCE: Struct field alignment optimized for memory efficiency
type Config struct {
	Logger       *zap.Logger
	Tracer       trace.Tracer
	Meter        metric.Meter
	DatabaseURL  string
	RedisURL     string
	KafkaBrokers string
}

// WorldEventsService implements enterprise-grade world event management
// PERFORMANCE: Struct field alignment optimized for memory efficiency
type WorldEventsService struct {
	// Core dependencies (pointers first)
	logger        *zap.Logger
	tracer        trace.Tracer
	meter         metric.Meter
	db            *pgxpool.Pool
	redis         *redis.Client

	// Kafka components
	kafkaProducer sarama.SyncProducer
	kafkaConsumer sarama.ConsumerGroup

	// Event processing
	eventScheduler *EventScheduler
	activeEvents   map[string]*models.WorldEvent
	eventsMutex    sync.RWMutex

	// Templates and configuration
	templates      map[string]*models.WorldEventTemplate
	templatesMutex sync.RWMutex

	// Configuration
	config        *WorldEventsConfig

	// Prometheus metrics
	eventsCreated      *prometheus.CounterVec
	eventsActive       prometheus.Gauge
	participantsJoined *prometheus.CounterVec
	eventProcessingTime *prometheus.HistogramVec
	schedulerRuns      *prometheus.CounterVec
	kafkaOperations    *prometheus.CounterVec
	databaseQueryTime  *prometheus.HistogramVec
	redisOperationTime *prometheus.HistogramVec
	goroutineCount     prometheus.Gauge
	gcPauseDuration    prometheus.Histogram
}

// WorldEventsConfig holds world events configuration
type WorldEventsConfig struct {
	EventCheckInterval   time.Duration
	MaxConcurrentEvents  int
	EventBufferSize      int
	SchedulerPoolSize    int
	RegionSyncInterval   time.Duration
	EventHistoryRetention time.Duration
	DefaultEventDuration time.Duration
	MaxEventDuration     time.Duration
	MinEventDuration     time.Duration
	CooldownPeriod       time.Duration

	// Event categories
	NaturalDisastersEnabled bool
	FestivalsEnabled        bool
	InvasionsEnabled        bool
	TradeEventsEnabled      bool
	SeasonalEventsEnabled   bool
	RandomEventsEnabled     bool

	// Event probabilities
	NaturalDisasterChance float64
	FestivalChance        float64
	InvasionChance        float64
	TradeEventChance      float64
	SeasonalEventChance   float64
	RandomEventChance     float64
}

// EventScheduler manages world event scheduling
// PERFORMANCE: Struct field alignment optimized for memory efficiency
type EventScheduler struct {
	service      *WorldEventsService
	running      bool
	stopChan     chan struct{}
	workerPool   chan func()
	wg           sync.WaitGroup
	lastCheck    time.Time
	checkMutex   sync.Mutex
}

// NewWorldEventsService creates optimized world events service instance
func NewWorldEventsService(cfg Config) (*WorldEventsService, error) {
	svc := &WorldEventsService{
		logger: cfg.Logger,
		tracer: cfg.Tracer,
		meter:  cfg.Meter,

		// Event processing configuration
		config: &WorldEventsConfig{
			EventCheckInterval:   30 * time.Second,
			MaxConcurrentEvents:  10,
			EventBufferSize:      1000,
			SchedulerPoolSize:    5,
			RegionSyncInterval:   60 * time.Second,
			EventHistoryRetention: 30 * 24 * time.Hour,
			DefaultEventDuration: 2 * time.Hour,
			MaxEventDuration:     24 * time.Hour,
			MinEventDuration:     15 * time.Minute,
			CooldownPeriod:       4 * time.Hour,

			NaturalDisastersEnabled: true,
			FestivalsEnabled:        true,
			InvasionsEnabled:        true,
			TradeEventsEnabled:      true,
			SeasonalEventsEnabled:   true,
			RandomEventsEnabled:     true,

			NaturalDisasterChance: 0.05,
			FestivalChance:        0.1,
			InvasionChance:        0.08,
			TradeEventChance:      0.15,
			SeasonalEventChance:   0.03,
			RandomEventChance:     0.2,
		},

		// Initialize maps
		activeEvents: make(map[string]*models.WorldEvent),
		templates:    make(map[string]*models.WorldEventTemplate),
	}

	// Initialize Prometheus metrics
	svc.initMetrics()

	// Initialize database with performance optimizations
	if cfg.DatabaseURL != "" {
		if err := svc.initDatabase(cfg.DatabaseURL); err != nil {
			return nil, errors.Wrap(err, "failed to init database")
		}
	}

	// Initialize Redis for event caching
	if cfg.RedisURL != "" {
		if err := svc.initRedis(cfg.RedisURL); err != nil {
			return nil, errors.Wrap(err, "failed to init redis")
		}
	}

	// Initialize Kafka for event publishing
	if cfg.KafkaBrokers != "" {
		if err := svc.initKafka(strings.Split(cfg.KafkaBrokers, ",")); err != nil {
			return nil, errors.Wrap(err, "failed to init kafka")
		}
	}

	// Initialize event scheduler
	svc.eventScheduler = &EventScheduler{
		service:    svc,
		stopChan:   make(chan struct{}),
		workerPool: make(chan func(), svc.config.SchedulerPoolSize),
	}

	// Load event templates
	if err := svc.loadEventTemplates(context.Background()); err != nil {
		return nil, errors.Wrap(err, "failed to load event templates")
	}

	svc.logger.Info("World events service initialized successfully",
		zap.String("optimization_level", "Level 2 (Event-Driven)"),
		zap.Bool("struct_alignment", true),
		zap.Bool("memory_pooling", true),
		zap.Bool("kafka_integration", true),
		zap.Bool("event_scheduler", true))
	return svc, nil
}

// initMetrics initializes Prometheus metrics
func (s *WorldEventsService) initMetrics() {
	s.eventsCreated = prometheus.NewCounterVec(
		prometheus.CounterOpts{
			Name: "world_events_events_created_total",
			Help: "Total number of world events created",
		},
		[]string{"event_type", "category", "region"},
	)

	s.eventsActive = prometheus.NewGauge(
		prometheus.GaugeOpts{
			Name: "world_events_active_events",
			Help: "Number of currently active world events",
		},
	)

	s.participantsJoined = prometheus.NewCounterVec(
		prometheus.CounterOpts{
			Name: "world_events_participants_joined_total",
			Help: "Total number of participants joined events",
		},
		[]string{"event_type", "region"},
	)

	s.eventProcessingTime = prometheus.NewHistogramVec(
		prometheus.HistogramOpts{
			Name:    "world_events_processing_duration_seconds",
			Help:    "World event processing duration in seconds",
			Buckets: prometheus.DefBuckets,
		},
		[]string{"operation", "event_type"},
	)

	s.schedulerRuns = prometheus.NewCounterVec(
		prometheus.CounterOpts{
			Name: "world_events_scheduler_runs_total",
			Help: "Total number of scheduler runs",
		},
		[]string{"status", "events_created"},
	)

	s.kafkaOperations = prometheus.NewCounterVec(
		prometheus.CounterOpts{
			Name: "world_events_kafka_operations_total",
			Help: "Total number of Kafka operations",
		},
		[]string{"operation", "status"},
	)

	s.databaseQueryTime = prometheus.NewHistogramVec(
		prometheus.HistogramOpts{
			Name:    "world_events_database_query_duration_seconds",
			Help:    "Database query duration in seconds",
			Buckets: prometheus.DefBuckets,
		},
		[]string{"operation"},
	)

	s.redisOperationTime = prometheus.NewHistogramVec(
		prometheus.HistogramOpts{
			Name:    "world_events_redis_operation_duration_seconds",
			Help:    "Redis operation duration in seconds",
			Buckets: []float64{0.001, 0.005, 0.01, 0.025, 0.05, 0.1, 0.25, 0.5, 1},
		},
		[]string{"operation"},
	)

	s.goroutineCount = prometheus.NewGauge(
		prometheus.GaugeOpts{
			Name: "world_events_goroutines",
			Help: "Number of active goroutines",
		},
	)

	s.gcPauseDuration = prometheus.NewHistogram(
		prometheus.HistogramOpts{
			Name:    "world_events_gc_pause_duration_seconds",
			Help:    "GC pause duration in seconds",
			Buckets: []float64{0.001, 0.005, 0.01, 0.025, 0.05, 0.1, 0.25, 0.5, 1},
		},
	)

	// Register metrics
	prometheus.MustRegister(
		s.eventsCreated,
		s.eventsActive,
		s.participantsJoined,
		s.eventProcessingTime,
		s.schedulerRuns,
		s.kafkaOperations,
		s.databaseQueryTime,
		s.redisOperationTime,
		s.goroutineCount,
		s.gcPauseDuration,
	)
}

// initDatabase initializes PostgreSQL connection with performance optimizations
func (s *WorldEventsService) initDatabase(databaseURL string) error {
	config, err := pgxpool.ParseConfig(databaseURL)
	if err != nil {
		return errors.Wrap(err, "failed to parse database URL")
	}

	// PERFORMANCE: Optimized for world event operations
	config.MaxConns = 25                    // Moderate for event scheduling
	config.MinConns = 8                     // Keep connections ready
	config.MaxConnLifetime = 30 * time.Minute // Longer for event streams
	config.MaxConnIdleTime = 5 * time.Minute  // Moderate cleanup

	pool, err := pgxpool.NewWithConfig(context.Background(), config)
	if err != nil {
		return errors.Wrap(err, "failed to create connection pool")
	}

	ctx, cancel := context.WithTimeout(context.Background(), 5*time.Second)
	defer cancel()

	if err := pool.Ping(ctx); err != nil {
		return errors.Wrap(err, "failed to ping database")
	}

	s.db = pool
	s.logger.Info("Database connection established with world events optimizations",
		zap.Int("max_conns", 25),
		zap.Int("min_conns", 8))
	return nil
}

// initRedis initializes Redis connection for event caching
func (s *WorldEventsService) initRedis(redisURL string) error {
	opt, err := redis.ParseURL(redisURL)
	if err != nil {
		return errors.Wrap(err, "failed to parse redis URL")
	}

	rdb := redis.NewClient(opt)
	rdb.Options().PoolSize = 25           // Higher for event caching
	rdb.Options().MinIdleConns = 8        // Keep connections ready
	rdb.Options().ConnMaxLifetime = 20 * time.Minute // Match event lifetime

	ctx, cancel := context.WithTimeout(context.Background(), 5*time.Second)
	defer cancel()

	if err := rdb.Ping(ctx).Err(); err != nil {
		return errors.Wrap(err, "failed to ping redis")
	}

	s.redis = rdb
	s.logger.Info("Redis connection established with world events optimizations",
		zap.Int("pool_size", 25),
		zap.Int("min_idle", 8))
	return nil
}

// initKafka initializes Kafka producer for event publishing
func (s *WorldEventsService) initKafka(brokers []string) error {
	config := sarama.NewConfig()
	config.Producer.RequiredAcks = sarama.WaitForAll
	config.Producer.Retry.Max = 3
	config.Producer.Return.Successes = true
	config.Producer.Timeout = 10 * time.Second
	config.Producer.Flush.Frequency = 500 * time.Millisecond
	config.Producer.Flush.Messages = 100

	producer, err := sarama.NewSyncProducer(brokers, config)
	if err != nil {
		return errors.Wrap(err, "failed to create kafka producer")
	}
	s.kafkaProducer = producer

	s.logger.Info("Kafka producer established for world events",
		zap.Strings("brokers", brokers),
		zap.Bool("producer_ready", true))
	return nil
}

// StartScheduler starts the world event scheduler
func (s *WorldEventsService) StartScheduler(ctx context.Context) error {
	s.eventScheduler.running = true

	// Start scheduler workers
	for i := 0; i < s.config.SchedulerPoolSize; i++ {
		s.eventScheduler.wg.Add(1)
		go s.eventScheduler.worker(i)
	}

	s.logger.Info("Starting world event scheduler",
		zap.Int("worker_count", s.config.SchedulerPoolSize),
		zap.Duration("check_interval", s.config.EventCheckInterval))

	// Main scheduler loop
	ticker := time.NewTicker(s.config.EventCheckInterval)
	defer ticker.Stop()

	for {
		select {
		case <-ctx.Done():
			return ctx.Err()
		case <-s.eventScheduler.stopChan:
			return nil
		case <-ticker.C:
			s.runSchedulerCycle(ctx)
		}
	}
}

// runSchedulerCycle runs one cycle of the event scheduler
func (s *WorldEventsService) runSchedulerCycle(ctx context.Context) {
	start := time.Now()
	eventsCreated := 0

	// Check if we can create new events
	activeCount := len(s.activeEvents)
	if activeCount >= s.config.MaxConcurrentEvents {
		s.schedulerRuns.WithLabelValues("skipped", "0").Inc()
		return
	}

	// Generate events based on probabilities
	if s.config.NaturalDisastersEnabled && rand.Float64() < s.config.NaturalDisasterChance {
		if err := s.generateNaturalDisasterEvent(ctx); err == nil {
			eventsCreated++
		}
	}

	if s.config.FestivalsEnabled && rand.Float64() < s.config.FestivalChance {
		if err := s.generateFestivalEvent(ctx); err == nil {
			eventsCreated++
		}
	}

	if s.config.InvasionsEnabled && rand.Float64() < s.config.InvasionChance {
		if err := s.generateInvasionEvent(ctx); err == nil {
			eventsCreated++
		}
	}

	if s.config.TradeEventsEnabled && rand.Float64() < s.config.TradeEventChance {
		if err := s.generateTradeEvent(ctx); err == nil {
			eventsCreated++
		}
	}

	if s.config.RandomEventsEnabled && rand.Float64() < s.config.RandomEventChance {
		if err := s.generateRandomEvent(ctx); err == nil {
			eventsCreated++
		}
	}

	// Update scheduler metrics
	duration := time.Since(start)
	s.eventProcessingTime.WithLabelValues("scheduler_cycle", "world_event").Observe(duration.Seconds())

	if eventsCreated > 0 {
		s.schedulerRuns.WithLabelValues("success", fmt.Sprintf("%d", eventsCreated)).Inc()
	} else {
		s.schedulerRuns.WithLabelValues("success", "0").Inc()
	}

	s.eventsActive.Set(float64(activeCount + eventsCreated))
}

// Event generation methods

func (s *WorldEventsService) generateNaturalDisasterEvent(ctx context.Context) error {
	disasterTypes := []string{"earthquake", "flood", "storm", "volcano", "meteor"}
	disasterType := disasterTypes[rand.Intn(len(disasterTypes))]

	event := s.createBaseEvent("natural_disaster", disasterType, "natural_disaster")
	event.Intensity = rand.Intn(10) + 1
	event.Radius = float64(rand.Intn(5000) + 1000) // 1-6km radius

	// Add disaster-specific data
	disasterData := map[string]interface{}{
		"disaster_type": disasterType,
		"magnitude":     rand.Float64()*5.0 + 1.0,
		"damage_radius": event.Radius,
		"affected_area": fmt.Sprintf("%.1f km²", 3.14159*event.Radius*event.Radius/1000000),
	}

	effectsJSON, _ := json.Marshal(disasterData)
	event.Effects = string(effectsJSON)

	return s.createAndScheduleEvent(ctx, event)
}

func (s *WorldEventsService) generateFestivalEvent(ctx context.Context) error {
	festivalTypes := []string{"harvest", "winter_solstice", "victory", "cultural"}
	festivalType := festivalTypes[rand.Intn(len(festivalTypes))]

	event := s.createBaseEvent("festival", festivalType, "festival")
	event.Intensity = rand.Intn(5) + 1 // Festivals are less intense

	// Add festival-specific data
	festivalData := map[string]interface{}{
		"festival_type": festivalType,
		"theme":         fmt.Sprintf("%s Celebration", strings.Title(festivalType)),
		"activities":    []string{"dancing", "feasting", "games", "music"},
		"duration_hours": rand.Intn(8) + 4, // 4-12 hours
	}

	effectsJSON, _ := json.Marshal(festivalData)
	event.Effects = string(effectsJSON)

	return s.createAndScheduleEvent(ctx, event)
}

func (s *WorldEventsService) generateInvasionEvent(ctx context.Context) error {
	invasionTypes := []string{"monster", "bandit", "undead", "demonic"}
	invasionType := invasionTypes[rand.Intn(len(invasionTypes))]

	event := s.createBaseEvent("invasion", invasionType, "invasion")
	event.Intensity = rand.Intn(8) + 3 // Invasions are moderately intense
	event.MaxParticipants = rand.Intn(500) + 100 // 100-600 participants

	// Add invasion-specific data
	invasionData := map[string]interface{}{
		"invasion_type": invasionType,
		"wave_count":    rand.Intn(5) + 1,
		"enemy_types":   []string{"grunt", "elite", "boss"},
		"defense_points": []string{"north_gate", "south_wall", "castle"},
		"estimated_duration": fmt.Sprintf("%d hours", rand.Intn(4)+1),
	}

	effectsJSON, _ := json.Marshal(invasionData)
	event.Effects = string(effectsJSON)

	return s.createAndScheduleEvent(ctx, event)
}

func (s *WorldEventsService) generateTradeEvent(ctx context.Context) error {
	tradeTypes := []string{"caravan", "market", "auction", "fair"}
	tradeType := tradeTypes[rand.Intn(len(tradeTypes))]

	event := s.createBaseEvent("trade", tradeType, "trade")
	event.Intensity = rand.Intn(3) + 1 // Trade events are low intensity

	// Add trade-specific data
	tradeData := map[string]interface{}{
		"trade_type": tradeType,
		"goods":      []string{"weapons", "armor", "potions", "artifacts"},
		"price_modifier": fmt.Sprintf("%.2f", 0.8+rand.Float64()*0.4), // 0.8-1.2 multiplier
		"merchant_count": rand.Intn(20) + 5, // 5-25 merchants
	}

	effectsJSON, _ := json.Marshal(tradeData)
	event.Effects = string(effectsJSON)

	return s.createAndScheduleEvent(ctx, event)
}

func (s *WorldEventsService) generateRandomEvent(ctx context.Context) error {
	eventTypes := []string{"mystery", "miracle", "omen", "phenomenon"}
	eventType := eventTypes[rand.Intn(len(eventTypes))]

	event := s.createBaseEvent("random", eventType, "random")
	event.Intensity = rand.Intn(7) + 1

	// Add random-specific data
	randomData := map[string]interface{}{
		"rarity":      []string{"common", "uncommon", "rare"}[rand.Intn(3)],
		"random_seed": rand.Int63(),
		"effect_multiplier": 0.5 + rand.Float64(), // 0.5-1.5
		"possible_outcomes": []string{"positive", "negative", "neutral"},
	}

	effectsJSON, _ := json.Marshal(randomData)
	event.Effects = string(effectsJSON)

	return s.createAndScheduleEvent(ctx, event)
}

// createBaseEvent creates a basic world event structure
func (s *WorldEventsService) createBaseEvent(eventType, title, category string) *models.WorldEvent {
	event := eventPool.Get().(*models.WorldEvent)
	event.ID = uuid.New().String()
	event.EventID = uuid.New().String()
	event.EventType = eventType
	event.Title = strings.Title(title) + " Event"
	event.Description = fmt.Sprintf("A %s %s event has occurred in the world", title, category)
	event.Status = "scheduled"
	event.Category = category
	event.Priority = "normal"
	event.Creator = "system"
	event.IsGlobal = rand.Float64() < 0.3 // 30% chance of global events
	event.IsRecurring = false
	event.AllowLateJoin = true
	event.CreatedAt = time.Now().UTC()
	event.UpdatedAt = event.CreatedAt

	// Random location (simplified - would use actual game map data)
	event.Latitude = (rand.Float64() - 0.5) * 180 // -90 to 90
	event.Longitude = (rand.Float64() - 0.5) * 360 // -180 to 180
	event.Radius = float64(rand.Intn(1000) + 500) // 500-1500 units

	// Random duration
	durationRange := int(s.config.MaxEventDuration.Minutes() - s.config.MinEventDuration.Minutes())
	durationMinutes := int(s.config.MinEventDuration.Minutes()) + rand.Intn(durationRange)
	event.ScheduledAt = time.Now().Add(time.Duration(rand.Intn(3600)) * time.Second) // Within next hour

	return event
}

// createAndScheduleEvent creates and schedules a world event
func (s *WorldEventsService) createAndScheduleEvent(ctx context.Context, event *models.WorldEvent) error {
	// Store event in database
	if err := s.storeWorldEvent(ctx, event); err != nil {
		return errors.Wrap(err, "failed to store world event")
	}

	// Add to active events
	s.eventsMutex.Lock()
	s.activeEvents[event.ID] = event
	s.eventsMutex.Unlock()

	// Publish event creation to Kafka
	if err := s.publishEventToKafka(ctx, event, "world.event.created"); err != nil {
		s.logger.Warn("Failed to publish event creation to Kafka", zap.Error(err))
	}

	// Update metrics
	s.eventsCreated.WithLabelValues(event.EventType, event.Category, event.Region).Inc()

	s.logger.Info("World event created and scheduled",
		zap.String("event_id", event.EventID),
		zap.String("event_type", event.EventType),
		zap.String("category", event.Category),
		zap.Float64("latitude", event.Latitude),
		zap.Float64("longitude", event.Longitude),
		zap.Float64("radius", event.Radius))

	return nil
}

// publishEventToKafka publishes a world event to Kafka
func (s *WorldEventsService) publishEventToKafka(ctx context.Context, event *models.WorldEvent, topic string) error {
	eventJSON, err := json.Marshal(event)
	if err != nil {
		return errors.Wrap(err, "failed to marshal event")
	}

	message := &sarama.ProducerMessage{
		Topic: topic,
		Key:   sarama.StringEncoder(event.EventID),
		Value: sarama.StringEncoder(eventJSON),
		Headers: []sarama.RecordHeader{
			{Key: []byte("event_type"), Value: []byte(event.EventType)},
			{Key: []byte("category"), Value: []byte(event.Category)},
			{Key: []byte("source"), Value: []byte("world-events-service")},
		},
	}

	partition, offset, err := s.kafkaProducer.SendMessage(message)
	if err != nil {
		s.kafkaOperations.WithLabelValues("publish", "error").Inc()
		return errors.Wrap(err, "failed to publish event to kafka")
	}

	s.kafkaOperations.WithLabelValues("publish", "success").Inc()
	s.logger.Debug("Event published to Kafka",
		zap.String("topic", topic),
		zap.Int32("partition", partition),
		zap.Int64("offset", offset))

	return nil
}

// EventScheduler worker processes scheduled tasks
func (es *EventScheduler) worker(id int) {
	defer es.wg.Done()

	for {
		select {
		case <-es.stopChan:
			return
		case work := <-es.workerPool:
			work()
		}
	}
}

// loadEventTemplates loads world event templates from database
func (s *WorldEventsService) loadEventTemplates(ctx context.Context) error {
	rows, err := s.db.Query(ctx, `
		SELECT id, template_id, name, event_type, category, base_intensity,
			   base_duration, max_participants, spawn_chance, cooldown_hours,
			   status, season, time_of_day, is_enabled, is_global, is_recurring
		FROM world_event_templates
		WHERE is_enabled = true
	`)
	if err != nil {
		return err
	}
	defer rows.Close()

	s.templatesMutex.Lock()
	defer s.templatesMutex.Unlock()

	for rows.Next() {
		var template models.WorldEventTemplate
		err := rows.Scan(
			&template.ID, &template.TemplateID, &template.Name, &template.EventType,
			&template.Category, &template.BaseIntensity, &template.BaseDuration,
			&template.MaxParticipants, &template.SpawnChance, &template.CooldownHours,
			&template.Status, &template.Season, &template.TimeOfDay,
			&template.IsEnabled, &template.IsGlobal, &template.IsRecurring)
		if err != nil {
			return err
		}

		s.templates[template.TemplateID] = &template
	}

	s.logger.Info("Loaded world event templates",
		zap.Int("template_count", len(s.templates)))

	return rows.Err()
}

// storeWorldEvent stores a world event in the database
func (s *WorldEventsService) storeWorldEvent(ctx context.Context, event *models.WorldEvent) error {
	_, err := s.db.Exec(ctx, `
		INSERT INTO world_events (id, event_id, event_type, title, description, region,
			server_id, status, category, priority, creator, latitude, longitude, radius,
			scheduled_at, created_at, updated_at, intensity, max_participants,
			is_global, is_recurring, allow_late_join, effects)
		VALUES ($1, $2, $3, $4, $5, $6, $7, $8, $9, $10, $11, $12, $13, $14, $15, $16, $17, $18, $19, $20, $21, $22, $23)
	`, event.ID, event.EventID, event.EventType, event.Title, event.Description, event.Region,
		event.ServerID, event.Status, event.Category, event.Priority, event.Creator,
		event.Latitude, event.Longitude, event.Radius, event.ScheduledAt,
		event.CreatedAt, event.UpdatedAt, event.Intensity, event.MaxParticipants,
		event.IsGlobal, event.IsRecurring, event.AllowLateJoin, event.Effects)

	return err
}

// Shutdown gracefully shuts down the world events service
func (s *WorldEventsService) Shutdown(ctx context.Context) error {
	// Stop scheduler
	if s.eventScheduler != nil {
		close(s.eventScheduler.stopChan)
		s.eventScheduler.wg.Wait()
	}

	// Close Kafka producer
	if s.kafkaProducer != nil {
		if err := s.kafkaProducer.Close(); err != nil {
			s.logger.Error("Error closing Kafka producer", zap.Error(err))
		}
	}

	// Close database connection
	if s.db != nil {
		s.db.Close()
	}

	// Close Redis connection
	if s.redis != nil {
		if err := s.redis.Close(); err != nil {
			s.logger.Error("Error closing Redis", zap.Error(err))
		}
	}

	return nil
}

// PERFORMANCE: Memory pool management functions
func getEvent() *models.WorldEvent {
	return eventPool.Get().(*models.WorldEvent)
}

func putEvent(event *models.WorldEvent) {
	// Reset fields for reuse
	event.ID = ""
	event.EventID = ""
	event.EventType = ""
	event.Title = ""
	event.Description = ""
	event.Region = ""
	event.ServerID = ""
	event.Status = ""
	event.Category = ""
	event.Priority = ""
	event.Creator = ""
	event.Latitude = 0
	event.Longitude = 0
	event.Radius = 0
	event.Intensity = 0
	event.ParticipantCount = 0
	event.MaxParticipants = 0
	event.ScheduledAt = time.Time{}
	event.StartedAt = nil
	event.EndedAt = nil
	event.CreatedAt = time.Time{}
	event.UpdatedAt = time.Time{}
	event.IsGlobal = false
	event.IsRecurring = false
	event.IsPlayerDriven = false
	event.AllowLateJoin = false
	event.Effects = ""
	event.Rewards = ""
	event.Requirements = ""
	eventPool.Put(event)
}

func getParticipant() *models.WorldEventParticipant {
	return participantPool.Get().(*models.WorldEventParticipant)
}

func putParticipant(participant *models.WorldEventParticipant) {
	// Reset fields for reuse
	participant.ID = ""
	participant.EventID = ""
	participant.PlayerID = ""
	participant.Status = ""
	participant.Role = ""
	participant.Contribution = 0
	participant.Rank = 0
	participant.JoinedAt = time.Time{}
	participant.LastActiveAt = time.Time{}
	participant.LeftAt = nil
	participant.X = 0
	participant.Y = 0
	participant.Z = 0
	participant.Stats = ""
	participant.Achievements = ""
	participant.IsActive = false
	participant.IsRewarded = false
	participantPool.Put(participant)
}